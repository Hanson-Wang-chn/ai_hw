{
  "position_encoding_relative": {
    "config": {
      "experiment": {
        "name": "position_encoding_relative",
        "description": "相对位置编码 (Shaw et al., 2018)，仅编码token间相对距离"
      },
      "model": {
        "d_model": 512,
        "nhead": 8,
        "num_encoder_layers": 3,
        "num_decoder_layers": 3,
        "dim_feedforward": 2048,
        "dropout": 0.1,
        "activation": "relu",
        "pe_type": "relative",
        "norm_type": "post",
        "attn_type": "multi_head"
      },
      "training": {
        "lr": 0.0001,
        "batch_size": 32,
        "epochs": 50,
        "patience": 5,
        "lr_patience": 3,
        "lr_factor": 0.5,
        "grad_clip": 1.0,
        "label_smoothing": 0.1,
        "weight_decay": 0.01
      },
      "data": {
        "max_seq_len": 20,
        "min_freq": 2
      }
    },
    "test_metrics": {
      "bleu_1": 0.02468094082902647,
      "bleu_2": 0.008018668483230665,
      "bleu_4": 0.004774925052524541,
      "rouge_l": 0.06117487462422324,
      "bert_score": 0.4818650186061859,
      "loss": 0.45005546789616346
    },
    "long_sentence_accuracy": 0.004940260421334742,
    "convergence_epoch": 1,
    "bleu_1": 0.02468094082902647,
    "bleu_2": 0.008018668483230665,
    "bleu_4": 0.004774925052524541,
    "rouge_l": 0.06117487462422324,
    "bert_score": 0.4818650186061859,
    "loss": 0.45005546789616346
  },
  "position_encoding_learnable": {
    "config": {
      "experiment": {
        "name": "position_encoding_learnable",
        "description": "可学习位置编码，嵌入层维度与词嵌入一致，随训练更新"
      },
      "model": {
        "d_model": 512,
        "nhead": 8,
        "num_encoder_layers": 3,
        "num_decoder_layers": 3,
        "dim_feedforward": 2048,
        "dropout": 0.1,
        "activation": "relu",
        "pe_type": "learnable",
        "norm_type": "post",
        "attn_type": "multi_head"
      },
      "training": {
        "lr": 0.0001,
        "batch_size": 32,
        "epochs": 50,
        "patience": 5,
        "lr_patience": 3,
        "lr_factor": 0.5,
        "grad_clip": 1.0,
        "label_smoothing": 0.1,
        "weight_decay": 0.01
      },
      "data": {
        "max_seq_len": 20,
        "min_freq": 2
      }
    },
    "test_metrics": {
      "bleu_1": 0.02468094082902647,
      "bleu_2": 0.008018668483230665,
      "bleu_4": 0.004774925052524541,
      "rouge_l": 0.06117487462422324,
      "bert_score": 0.4818650186061859,
      "loss": 0.45051604975014925
    },
    "long_sentence_accuracy": 0.004940260421334742,
    "convergence_epoch": 1,
    "bleu_1": 0.02468094082902647,
    "bleu_2": 0.008018668483230665,
    "bleu_4": 0.004774925052524541,
    "rouge_l": 0.06117487462422324,
    "bert_score": 0.4818650186061859,
    "loss": 0.45051604975014925
  },
  "position_encoding_sinusoidal": {
    "config": {
      "experiment": {
        "name": "position_encoding_sinusoidal",
        "description": "标准正弦位置编码 (Vaswani et al., 2017)"
      },
      "model": {
        "d_model": 512,
        "nhead": 8,
        "num_encoder_layers": 3,
        "num_decoder_layers": 3,
        "dim_feedforward": 2048,
        "dropout": 0.1,
        "activation": "relu",
        "pe_type": "sinusoidal",
        "norm_type": "post",
        "attn_type": "multi_head"
      },
      "training": {
        "lr": 0.0001,
        "batch_size": 32,
        "epochs": 50,
        "patience": 5,
        "lr_patience": 3,
        "lr_factor": 0.5,
        "grad_clip": 1.0,
        "label_smoothing": 0.1,
        "weight_decay": 0.01
      },
      "data": {
        "max_seq_len": 20,
        "min_freq": 2
      }
    },
    "test_metrics": {
      "bleu_1": 0.02468094082902647,
      "bleu_2": 0.008018668483230665,
      "bleu_4": 0.004774925052524541,
      "rouge_l": 0.06117487462422324,
      "bert_score": 0.4818650186061859,
      "loss": 0.576075192540884
    },
    "long_sentence_accuracy": 0.004940260421334742,
    "convergence_epoch": 1,
    "bleu_1": 0.02468094082902647,
    "bleu_2": 0.008018668483230665,
    "bleu_4": 0.004774925052524541,
    "rouge_l": 0.06117487462422324,
    "bert_score": 0.4818650186061859,
    "loss": 0.576075192540884
  }
}